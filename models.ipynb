{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "features used for the first submission\n",
    "    features = [ 'Helpfulness', \n",
    "                'HelpfulnessDenominator', \n",
    "                'Average_Title_Sentiment' , \n",
    "                'Average_Text_Sentiment' , \n",
    "                'Review_Length', \n",
    "                'Time', \n",
    "                'Vader_Sentiment_Title',\n",
    "                'Vader_Sentiment_Text',\n",
    "                'TextBlob_Sentiment_Title',\n",
    "                'TextBlob_Sentiment_Text', \n",
    "                'Non_Alpha_Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "lgb_model.fit(X_train_select, Y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "Y_pred = lgb_model.predict(X_test_select)\n",
    "accuracy = accuracy_score(Y_test, Y_pred) * 100\n",
    "print(f\"LightGBM Accuracy: {accuracy:.2f}%\")\n",
    "return lgb_model, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(\n",
    "                    n_estimators=100,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=5\n",
    "                )       \n",
    "    # Train the model\n",
    "    model.fit(X_train_select, Y_train)\n",
    "                \n",
    "        # Make predictions\n",
    "    Y_test_predictions = model.predict(X_test_select)\n",
    "    # Calculate and display the final accuracy\n",
    "    final_accuracy = accuracy_score(Y_test, Y_test_predictions) * 100\n",
    "    print(f\"\\nFinal Accuracy (Using Best Gradient Boosting Model): {final_accuracy:.2f}%\")\n",
    "    return model, Y_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 4, 5]}\n",
    "    # Initialize variables to track the best model and accuracy\n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    best_params = {}\n",
    "\n",
    "    # Custom grid search loop\n",
    "    for n_estimators in param_grid['n_estimators']:\n",
    "        for learning_rate in param_grid['learning_rate']:\n",
    "            for max_depth in param_grid['max_depth']:\n",
    "                # Initialize the model with the current parameters\n",
    "                model = GradientBoostingClassifier(\n",
    "                    n_estimators=n_estimators,\n",
    "                    learning_rate=learning_rate,\n",
    "                    max_depth=max_depth\n",
    "                )\n",
    "                \n",
    "                # Train the model\n",
    "                model.fit(X_train_select, Y_train)\n",
    "                \n",
    "                # Make predictions\n",
    "                Y_test_predictions = model.predict(X_test_select)\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                accuracy = accuracy_score(Y_test, Y_test_predictions) * 100\n",
    "                print(f\"Params: n_estimators={n_estimators}, \"\n",
    "                    f\"learning_rate={learning_rate}, max_depth={max_depth} -> \"\n",
    "                    f\"Accuracy: {accuracy:.2f}%\")\n",
    "                \n",
    "                # Track the best model\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_model = model\n",
    "                    best_params = {\n",
    "                        'n_estimators': n_estimators,\n",
    "                        'learning_rate': learning_rate,\n",
    "                        'max_depth': max_depth\n",
    "                    }\n",
    "\n",
    "    print(f\"\\nBest Parameters: {best_params}\")\n",
    "    print(f\"Best Accuracy: {best_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define classifiers and their parameter grids\n",
    "classifiers = {\n",
    "    'Logistic Regression': (LogisticRegression(max_iter=1000), {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    }),\n",
    "    'Random Forest': (RandomForestClassifier(), {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5]\n",
    "    }),\n",
    "    'Gradient Boosting': (GradientBoostingClassifier(), {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 4, 5]\n",
    "    }),\n",
    "    'SVM': (SVC(), {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    })\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, (clf, param_grid) in classifiers.items():\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train_select, Y_train)\n",
    "    results[name] = grid_search.best_score_\n",
    "\n",
    "# Print the results\n",
    "for model, score in results.items():\n",
    "    print(f\"{model}: Best CV Score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Function to find the optimal constant (e.g., via cross-validation)\n",
    "def find_best_constant(X_train, Y_train, features):\n",
    "    param_grid = {'constant': np.linspace(10, 1000, 10)}  # Constants between 10 and 1000\n",
    "    best_score = -np.inf\n",
    "    best_constant = None\n",
    "\n",
    "    for c in param_grid['constant']:\n",
    "        # Create a temporary copy of the training data with scaled sentiment\n",
    "        X_train_temp = X_train.copy()\n",
    "        X_train_temp['Sentiment_Score'] = X_train_temp['Sentiment_Score'] / c\n",
    "\n",
    "        # Select only the relevant numerical features for the model\n",
    "        X_train_features = X_train_temp[features]\n",
    "\n",
    "        # Initialize the KNN classifier\n",
    "        knn = KNeighborsClassifier(n_neighbors=12)\n",
    "\n",
    "        # Evaluate the model using cross-validation (5 folds)\n",
    "        scores = cross_val_score(knn, X_train_features, Y_train, cv=5, scoring='accuracy')\n",
    "        mean_score = np.mean(scores)\n",
    "\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_constant = c\n",
    "\n",
    "    print(f\"Best constant: {best_constant} with score: {best_score}\")\n",
    "    return best_constant\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
